# Smart Home Voice Assistant
**An intelligent home automation system integrating speech, computer vision, and contextual reasoning for daily assistance.**

---

## Overview
This project provides a **smart home automation system** designed to enhance convenience and accessibility for users through natural voice interaction and adaptive behavior learning.  
The assistant can handle **voice commands**, **respond with speech**, and **interact with physical devices**.  
It also learns user behavior patterns via object tracking to provide smarter and more personalized responses.

---

## Key Features
- ğŸ™ï¸ **Voice Interaction:** Vietnamese speech recognition, wake word detection, and text-to-speech responses.  
- ğŸ§  **Intelligent Understanding:** Contextual command interpretation using Rasa NLU.  
- ğŸ§© **Behavior Learning:** Object tracking and activity detection via YOLO and DeepSORT.  
- âš™ï¸ **Home Control:** Manage lights, music, and other connected devices.  
- ğŸ—ºï¸ **Location Awareness:** Vietnamese geographic database for localized responses.  

---

## Technical Summary
### ğŸ§± Models and Frameworks
| Component | Model / Tool | Description |
|------------|---------------|-------------|
| **Speech-to-Text (STT)** | PhoWhisper | Fine-tuned for Vietnamese accents |
| **Text-to-Speech (TTS)** | Viettel TTS | Generates natural Vietnamese speech responses |
| **Wakeword Detection** | Porcupine | Activates system on wake phrase |
| **Language Understanding** | Rasa NLU | Extracts user intent and entities |
| **Object Tracking** | YOLOv8 + DeepSORT | Learns behavior from user activity |

### ğŸ§© Customizations
- Fine-tuned **PhoWhisper** model for niche Vietnamese accents using collected data.  
- Extended Rasaâ€™s knowledge base for Vietnamese commands and multi-turn conversations.  
- Integrated YOLOv8 and DeepSORT pipelines for visual learning.

---

## System Architecture (Simplified)

```
WakeWord â†’ PhoWhisper_Server (STT) â†’ Rasa Agent â†’ Action Server â†’ Smart Device / Feedback
                                       â†— 
            Object Tracking (YOLO + DeepSORT)
```

- **WakeWord:** Activates the system upon keyword detection.  
- **PhoWhisper Server:** Receives audio and returns transcription.  
- **Rasa Agent:** Interprets command intent and routes to proper action.  
- **Object Tracking:** Monitors user activity to send suitable responses.  
- **VoiceAssistant:** Executes commands and provides spoken feedback.

---

## Project Structure (Simplified)
```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ geo/                 # Vietnamese geographic dataset
â”œâ”€â”€ Object Tracking/     # YOLO + DeepSORT modules
â”œâ”€â”€ PhoWhisper_Server/   # Speech recognition API
â”œâ”€â”€ VoiceAssistant/      # Core Rasa NLU assistant logic
â”œâ”€â”€ WakeWord/            # Wakeword detection module
â”œâ”€â”€ Process_Data_File/   # Tools for preparing training data
â”œâ”€â”€ Test/                # Evaluation and experimental scripts
â””â”€â”€ audio.wav            # Sample input
```

Each module works as an independent component communicating through internal triggers or APIs.

---

## Installation & Setup

### ğŸ§° Prerequisites
- Python 3.9+  
- `pip` and virtual environment recommended  
- GPU (optional) for YOLO-based tracking

### âš™ï¸ Installation Steps
```bash
# 1. Clone repository
git clone https://github.com/DianPham/Python_AI_SmartHouse.git
cd Python_AI_SmartHouse

# 2. Install dependencies
pip install -r requirements.txt

# 3. Start PhoWhisper server
cd PhoWhisper_Server
python init_server.py

# 4. Start Rasa agent
cd VoiceAssistant/Rasa
rasa run --enable-api --cors "*"

# 5. Run wakeword detection
cd WakeWord
python ww_interact.py
```

---

## How to Use

1. Ensure **PhoWhisper server**, **Rasa agent**, and **Wakeword** modules are running.  
2. Say the defined wakeword to activate the assistant.  
3. Give voice commands such as:  
   - â€œTurn on the lights.â€  
   - â€œPlay Rising.mp3.â€  
   - â€œWhatâ€™s on my calendar today?â€  
4. The system will process, respond, and execute the corresponding action.  

---

## Example Workflow
```
[Wakeword detected] â†’ Capture user audio
â†’ Send to PhoWhisper_Server â†’ Get transcription
â†’ Rasa interprets command â†’ Trigger action or response
â†’ Output speech via Viettel TTS
â†’ (Optional) Object tracking monitors environment
```

---

## Results and Performance
- Fine-tuned PhoWhisper improved WER by ~8% on Vietnamese speech.  
- Smooth wakeword detection and command processing with minimal latency.  
- Successful home device interactions (music, light control, calendar, email).  
- Integrated object tracking for adaptive behavior learning.

---

## Folder Highlights

- **VoiceAssistant/Rasa/** â€” Command interpretation and response logic.  
- **PhoWhisper_Server/** â€” STT model server with custom logging.  
- **WakeWord/** â€” Porcupine wakeword model and interaction scripts.  
- **Object Tracking/** â€” Behavior analysis using YOLOv8 + DeepSORT.  
- **Process_Data_File/** â€” Tools for cleaning and preparing voice datasets.  
- **Test/** â€” Component-specific evaluation scripts.

---

## Team & Credits
- **Dian Pham** â€” Project Lead, System Architect, AI Integration  
- **Van-Hai Ha** â€” Object Tracking, Data Preprocessing, Debugging  
- **Phuc-Dat Nguyen** â€” Object Tracking, Testing, Reporting

---

## License & Ethics
- For **educational and research use** only.  
- Respect licenses of third-party models and APIs.  
- Handle user data ethically and comply with privacy standards.

---

## Contact
**Dian Pham** â€” dianpham.ai@gmail.com  
GitHub: [DianPham](https://github.com/DianPham)
